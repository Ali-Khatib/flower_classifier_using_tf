{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "import tensorflow as tf\n", "import tensorflow_hub as hub\n", "import tensorflow_datasets as tfds\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from tensorflow.keras import layers, models\n", "from tensorflow.keras.models import load_model\n", "from PIL import Image\n", "from tensorflow.keras.preprocessing import image\n", "import json\n", "\n", "# Load the dataset with TensorFlow Datasets.\n", "dataset, info=tfds.load('oxford_flowers102', with_info=True, as_supervised=True)\n", "train_ds= dataset['train']\n", "test_ds= dataset['test']\n", "\n", "# Create a training set and validation set\n", "val_size=int(0.2 * info.splits['train'].num_examples)\n", "train_size=info.splits['train'].num_examples-val_size\n", "\n", "train_val_ds = train_ds\n", "train_ds=train_val_ds.take(train_size)\n", "val_ds=train_val_ds.skip(train_size)\n", "\n", "num_train_examples = info.splits['train'].num_examples\n", "print(f'Number of training examples: {num_train_examples}')\n", "\n", "num_test_examples = info.splits['test'].num_examples\n", "print(f'Number of test examples: {num_test_examples}')\n", "\n", "# Get the number of classes in the dataset from the dataset info.\n", "num_classes=info.features['label'].num_classes\n", "print(f'Number of classes is: {num_classes}')\n", "\n", "# Get the first 3 images and labels\n", "for i, (image_, label) in enumerate(train_ds.take(3)):\n", "    print(f'Image {i+1} shape: {image_.shape}, Label: {label.numpy()}')\n", "    plt.imshow(image_.numpy().astype(\"uint8\"))\n", "    plt.title(f'Label: {label.numpy()}')\n", "    plt.axis('off')\n", "    plt.show()\n", "\n", "# Sample image display\n", "plt.imshow(image_.numpy().astype('uint8'))\n", "plt.title(f'Label: {label.numpy()}')\n", "plt.axis('off')\n", "plt.show()\n", "\n", "# Load class names\n", "with open('label_map.json', 'r') as f:\n", "    class_names = json.load(f)\n", "\n", "sample_image, sample_label = next(iter(train_ds))\n", "class_name = class_names[str(sample_label.numpy())]\n", "\n", "plt.imshow(sample_image.numpy())\n", "plt.axis('off')\n", "plt.title(class_name)\n", "plt.show()\n", "\n", "# Preprocess function\n", "\n", "def preprocess_image(image_path):\n", "    img = image.load_img(image_path, target_size=(224, 224))\n", "    img_array = image.img_to_array(img)\n", "    img_array /= 255.0\n", "    img_array = np.expand_dims(img_array, axis=0)\n", "    return img_array\n", "\n", "# Model definition\n", "model = models.Sequential([\n", "    layers.Flatten(input_shape=(224, 224, 3)),\n", "    layers.Dense(256, activation='relu'),\n", "    layers.Dropout(0.3),\n", "    layers.Dense(num_classes, activation='softmax')\n", "])\n", "\n", "model.compile(optimizer='adam',\n", "              loss='sparse_categorical_crossentropy',\n", "              metrics=['accuracy'])\n", "\n", "# Train the model\n", "history = model.fit(train_ds.batch(64), validation_data=val_ds.batch(64), epochs=10)\n", "\n", "# Plot training and validation accuracy\n", "plt.plot(history.history['accuracy'], label='Train Accuracy')\n", "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n", "plt.xlabel('Epochs')\n", "plt.ylabel('Accuracy')\n", "plt.legend()\n", "plt.title('Training and Validation Accuracy')\n", "plt.show()\n", "\n", "# Plot training and validation loss\n", "plt.plot(history.history['loss'], label='Train Loss')\n", "plt.plot(history.history['val_loss'], label='Validation Loss')\n", "plt.xlabel('Epochs')\n", "plt.ylabel('Loss')\n", "plt.legend()\n", "plt.title('Training and Validation Loss')\n", "plt.show()\n", "\n", "# Evaluate on test set\n", "test_loss, test_accuracy = model.evaluate(test_ds.batch(64))\n", "print(f'Test Loss: {test_loss:.4f}')\n", "print(f'Test Accuracy: {test_accuracy:.4f}')\n", "\n", "# Save model\n", "model.save('flower_classifier.keras')\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}